{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LUNA-HYUN/HelmetDetectionV0/blob/main/HelmetDetectionV0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMebuha24Yml"
      },
      "outputs": [],
      "source": [
        "'''ë³¸ ì½”ë“œëŠ” Google Colabì—ì„œ GPUë¥¼ ì‚¬ìš©í•´ ì‹¤í–‰í•œë‹¤ëŠ” ê°€ì •í•˜ì— ì‘ì„±í–ˆìŠµë‹ˆë‹¤.'''\n",
        "\n",
        "# ==================================================================================\n",
        "# 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„ (Environment Setup & Data Preparation)\n",
        "# ==================================================================================\n",
        "print(\">> [1. Setup] í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì • ì¤‘...\")\n",
        "!pip install ultralytics kagglehub -q\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import yaml\n",
        "import cv2\n",
        "import torch\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# í•˜ë“œì›¨ì–´ ê°€ì†(GPU) ì„¤ì • í™•ì¸\n",
        "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"âœ… ì‚¬ìš© ì¥ì¹˜(Device): {torch.cuda.get_device_name(0) if DEVICE == 0 else 'CPU'}\")\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# 2. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ìƒì„¸ ë¶„ì„ (Dataset Analysis)\n",
        "# ----------------------------------------------------------------------------------\n",
        "print(\"\\n>> [2. Data] ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ë¬´ê²°ì„± ê²€ì‚¬...\")\n",
        "try:\n",
        "    dataset_path = kagglehub.dataset_download(\"muhammetzahitaydn/hardhat-vest-dataset-v3\")\n",
        "    print(f\"ğŸ“‚ ë°ì´í„°ì…‹ ì €ì¥ ê²½ë¡œ: {dataset_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# í´ë” êµ¬ì¡° ìë™ íƒìƒ‰\n",
        "images_root = os.path.join(dataset_path, 'images')\n",
        "if not os.path.exists(images_root): images_root = dataset_path\n",
        "\n",
        "subdirs = os.listdir(images_root)\n",
        "train_dir = next((d for d in subdirs if 'train' in d), None)\n",
        "val_dir = next((d for d in ['valid', 'val', 'validation'] if d in subdirs), None)\n",
        "test_dir = next((d for d in subdirs if 'test' in d), None)\n",
        "\n",
        "# [ìƒì„¸ ì •ë³´ 0] í´ë” êµ¬ì¡° í‘œì‹œ\n",
        "print(\"\\nğŸ“‚ í´ë” êµ¬ì¡°:\")\n",
        "def print_folder_structure(startpath):\n",
        "    for root, dirs, files in os.walk(startpath):\n",
        "        level = root.replace(startpath, '').count(os.sep)\n",
        "        indent = ' ' * 3 * (level)\n",
        "        if level == 0:\n",
        "            print(f\"   ğŸ“ {os.path.basename(root)}/\") # ê¸°ë³¸ í´ë” ì´ë¦„\n",
        "        else:\n",
        "            # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ ìˆ˜ ê³„ì‚°\n",
        "            file_count = len(files)\n",
        "            dir_name = os.path.basename(root)\n",
        "            if dir_name:\n",
        "                print(f\"{indent}   ğŸ“ {dir_name}/: {file_count}ê°œ íŒŒì¼\")\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ê²½ë¡œì˜ ë£¨íŠ¸ì— ìˆëŠ” íŒŒì¼ ì²˜ë¦¬ (ì˜ˆ: README ë˜ëŠ” data.yaml)\n",
        "    root_files = [f for f in os.listdir(startpath) if os.path.isfile(os.path.join(startpath, f))]\n",
        "    if root_files:\n",
        "        print(' ' * 3)\n",
        "        for f in root_files:\n",
        "            print(f\"   ğŸ“„ {f}\")\n",
        "\n",
        "print_folder_structure(dataset_path)\n",
        "\n",
        "# [ìƒì„¸ ì •ë³´ 1] ì´ë¯¸ì§€ ìˆ˜ í™•ì¸\n",
        "print(\"\\nğŸ“Š [ë°ì´í„°ì…‹ í†µê³„ - ì´ë¯¸ì§€ ìˆ˜ëŸ‰]\")\n",
        "data_dirs = {'Train': train_dir, 'Valid': val_dir, 'Test': test_dir}\n",
        "total_images = 0\n",
        "for name, d in data_dirs.items():\n",
        "    if d:\n",
        "        count_jpg = len(glob.glob(os.path.join(images_root, d, '*.jpg')))\n",
        "        count_png = len(glob.glob(os.path.join(images_root, d, '*.png')))\n",
        "        count = count_jpg + count_png\n",
        "        print(f\"   - {name} Set: {count}ì¥\")\n",
        "        total_images += count\n",
        "print(f\"   ğŸ‘‰ ì´ ì´ë¯¸ì§€ ìˆ˜: {total_images}ì¥\")\n",
        "\n",
        "\n",
        "# [ìƒì„¸ ì •ë³´ 2] ë¼ë²¨ ë°ì´í„° ë¶„í¬ ë¶„ì„ (í´ë˜ìŠ¤ë³„ ê°œìˆ˜)\n",
        "print(\"\\nğŸ“Š [ë°ì´í„°ì…‹ í†µê³„ - í´ë˜ìŠ¤ ë¶„í¬]\")\n",
        "# í´ë˜ìŠ¤ ì •ì˜ (0:Helmet, 1:Vest, 2:Head, 3:Person)\n",
        "class_names = {0: 'Helmet', 1: 'Vest', 2: 'Head', 3: 'Person'}\n",
        "label_counts = Counter()\n",
        "\n",
        "# Train ë¼ë²¨ íŒŒì¼ ì „ì²´ ìŠ¤ìº”\n",
        "train_label_path = os.path.join(dataset_path, 'labels', train_dir) if os.path.exists(os.path.join(dataset_path, 'labels')) else os.path.join(dataset_path, 'train', 'labels')\n",
        "if os.path.exists(train_label_path):\n",
        "    label_files = glob.glob(os.path.join(train_label_path, '*.txt'))\n",
        "    for lf in label_files:\n",
        "        with open(lf, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    cls_id = int(line.split()[0])\n",
        "                    label_counts[cls_id] += 1\n",
        "                except: pass\n",
        "\n",
        "# ë¶„í¬ ì¶œë ¥\n",
        "df_stats = pd.DataFrame.from_dict(label_counts, orient='index', columns=['Count'])\n",
        "df_stats.index = df_stats.index.map(class_names)\n",
        "print(df_stats.sort_values('Count', ascending=False))\n",
        "print(f\"   ğŸ‘‰ Head(2)ì™€ Helmet(0) ë°ì´í„°ê°€ í’ë¶€í•¨ í™•ì¸ë¨.\")\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# 3. ë°ì´í„° ì„¤ì • íŒŒì¼(YAML) ìƒì„± (Configuration)\n",
        "# ----------------------------------------------------------------------------------\n",
        "print(\"\\n>> [3. Config] í•™ìŠµ ì„¤ì • íŒŒì¼(data.yaml) ìƒì„±...\")\n",
        "yaml_path = '/content/safety_data.yaml'\n",
        "yaml_content = {\n",
        "    'path': dataset_path,\n",
        "    'train': os.path.join('images', train_dir),\n",
        "    'val': os.path.join('images', val_dir),\n",
        "    'nc': 4,\n",
        "    'names': ['Helmet', 'Vest', 'Head', 'Person']\n",
        "}\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(yaml_content, f, sort_keys=False)\n",
        "print(f\"âœ… ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------------\n",
        "# 4. ëª¨ë¸ ë¡œë“œ ë° í•™ìŠµ (Model Training)\n",
        "# ----------------------------------------------------------------------------------\n",
        "print(\"\\n>> [4. Train] YOLOv8 ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
        "model = YOLO('yolov8s.pt')  # Pre-trained ëª¨ë¸ ë¡œë“œ\n",
        "\n",
        "# í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • (ì²¨ë¶€íŒŒì¼ íŒŒì´í”„ë¼ì¸ ì°¸ì¡°)\n",
        "project_name = 'safety_project_final'\n",
        "results = model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=20,          # ì „ì²´ ë°ì´í„° ë°˜ë³µ í•™ìŠµ íšŸìˆ˜\n",
        "    imgsz=640,          # ì´ë¯¸ì§€ ì…ë ¥ í¬ê¸°\n",
        "    batch=32,           # ë°°ì¹˜ ì‚¬ì´ì¦ˆ (T4 GPU ìµœì í™”)\n",
        "    patience=5,         # ì¡°ê¸° ì¢…ë£Œ (ê³¼ì í•© ë°©ì§€)\n",
        "    workers=4,          # ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜\n",
        "    device=DEVICE,\n",
        "    project='/content/runs/detect',\n",
        "    name=project_name,\n",
        "    exist_ok=True,\n",
        "    verbose=True\n",
        ")\n",
        "print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "VTi5DIWiN_Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------------\n",
        "# 5. í•™ìŠµ ê²°ê³¼ ë¶„ì„ (Evaluation Visualization)\n",
        "# ----------------------------------------------------------------------------------\n",
        "print(\"\\n>> [5. Eval] í•™ìŠµ ê²°ê³¼ ì‹œê°í™”...\")\n",
        "results_dir = f'/content/runs/detect/{project_name}'\n",
        "\n",
        "# ê²°ê³¼ ê·¸ë˜í”„ (Loss, mAP)\n",
        "results_img = os.path.join(results_dir, 'results.png')\n",
        "if os.path.exists(results_img):\n",
        "    print(\"ğŸ“ˆ [í•™ìŠµ ê³¡ì„  (Loss & mAP)]\")\n",
        "    display(Image(results_img, width=800))\n",
        "\n",
        "# í˜¼ë™ í–‰ë ¬ (Confusion Matrix)\n",
        "cm_img = os.path.join(results_dir, 'confusion_matrix.png')\n",
        "if os.path.exists(cm_img):\n",
        "    print(\"ğŸ“‰ [í˜¼ë™ í–‰ë ¬ (Confusion Matrix)]\")\n",
        "    display(Image(cm_img, width=600))\n",
        "else:\n",
        "    print(\"âš ï¸ í˜¼ë™ í–‰ë ¬ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(f\"\\nâœ… ìµœì  ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {os.path.join(results_dir, 'weights', 'best.pt')}\")"
      ],
      "metadata": {
        "id": "QubHpZDXN_Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# 6. ì¶”ë¡  ë° ì‹œê°í™” (Inference and Visualization)\n",
        "# ==================================================================================\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "import glob\n",
        "import os\n",
        "\n",
        "print(\">> [6. Inference] ìŠ¤ë§ˆíŠ¸ ì•ˆì „ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê°€ë™...\")\n",
        "\n",
        "# 1. í•™ìŠµëœ ìµœì  ëª¨ë¸ ë¡œë“œ\n",
        "try:\n",
        "    best_model_path = '/content/runs/detect/safety_project_final/weights/best.pt'\n",
        "    model = YOLO(best_model_path)\n",
        "    print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {os.path.basename(best_model_path)}\")\n",
        "except:\n",
        "    print(\"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Part 1 í•™ìŠµì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "    model = None\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# ìœ„í—˜ êµ¬ì—­(Danger Zone) ê¸°ë°˜ 4ìƒ‰ ì•ˆì „ íŒë³„ ë¡œì§\n",
        "# ----------------------------------------------------------------------------------\n",
        "def draw_danger_zone(img, points):\n",
        "    \"\"\"ì´ë¯¸ì§€ì— ë°˜íˆ¬ëª…í•œ ìœ„í—˜ êµ¬ì—­(Red Zone)ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.\"\"\"\n",
        "    overlay = img.copy()\n",
        "    cv2.fillPoly(overlay, [points], (0, 0, 255)) # ë¹¨ê°„ìƒ‰ ì˜ì—­\n",
        "    alpha = 0.3 # íˆ¬ëª…ë„\n",
        "    cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)\n",
        "    cv2.polylines(img, [points], True, (0, 0, 255), 3) # í…Œë‘ë¦¬\n",
        "\n",
        "    # êµ¬ì—­ ì´ë¦„ í‘œì‹œ\n",
        "    m = cv2.moments(points)\n",
        "    if m[\"m00\"] != 0:\n",
        "        cx, cy = int(m[\"m10\"] / m[\"m00\"]), int(m[\"m01\"] / m[\"m00\"])\n",
        "        cv2.putText(img, \"DANGER ZONE\", (cx - 60, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "def is_in_zone(box, zone_points):\n",
        "    \"\"\"ì‘ì—…ìê°€ ìœ„í—˜ êµ¬ì—­ ë‚´ë¶€ì— ìˆëŠ”ì§€ íŒë³„í•©ë‹ˆë‹¤ (Point inside Polygon).\"\"\"\n",
        "    x1, y1, x2, y2 = box\n",
        "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2 # ì‘ì—…ìì˜ ì¤‘ì‹¬ì \n",
        "    return cv2.pointPolygonTest(zone_points, (cx, cy), False) >= 0\n",
        "\n",
        "def run_safety_analysis(model, image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None: return\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # 1. ìœ„í—˜ êµ¬ì—­ ì •ì˜ (ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤: í™”ë©´ ì¤‘ì•™ í•˜ë‹¨ì´ ìœ„í—˜ êµ¬ì—­)\n",
        "    zone_pts = np.array([\n",
        "        [int(w*0.2), int(h*0.3)], [int(w*0.8), int(h*0.3)],\n",
        "        [int(w*0.9), int(h*0.9)], [int(w*0.1), int(h*0.9)]\n",
        "    ], np.int32)\n",
        "    draw_danger_zone(img, zone_pts)\n",
        "\n",
        "    # 2. ëª¨ë¸ ì¶”ë¡  (Confidence 0.25)\n",
        "    results = model.predict(image_path, conf=0.25, verbose=False)\n",
        "    if not results: return\n",
        "\n",
        "    # 3. ê°ì²´ ë¶„ì„ ë° ìƒíƒœ íŒì •\n",
        "    for box in results[0].boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        cls_name = model.names[cls_id].lower()\n",
        "        xyxy = box.xyxy[0].cpu().numpy()\n",
        "        x1, y1, x2, y2 = map(int, xyxy)\n",
        "\n",
        "        # 'Helmet'(ì•ˆì „) ë˜ëŠ” 'Head'(ìœ„í—˜) í´ë˜ìŠ¤ë§Œ ë¶„ì„ ëŒ€ìƒ\n",
        "        has_helmet = 'helmet' in cls_name\n",
        "        is_head = 'head' in cls_name\n",
        "\n",
        "        if not (has_helmet or is_head): continue\n",
        "\n",
        "        # ìœ„ì¹˜ í™•ì¸: êµ¬ì—­ ë‚´ë¶€ì¸ê°€?\n",
        "        in_zone = is_in_zone(xyxy, zone_pts)\n",
        "\n",
        "        # --- [í•µì‹¬] 4ë‹¨ê³„ ìƒ‰ìƒ ì½”ë“œ (Color Code) ---\n",
        "        if in_zone:\n",
        "            if has_helmet:\n",
        "                color, label = (0, 255, 0), \"Authorized (In Zone)\"  # ğŸŸ¢ êµ¬ì—­ ë‚´ ìŠ¹ì¸ë¨\n",
        "            else:\n",
        "                color, label = (0, 0, 255), \"CRITICAL: LEAVE ZONE!\" # ğŸ”´ êµ¬ì—­ ë‚´ í—¬ë©§ ë¯¸ì°©ìš©\n",
        "        else:\n",
        "            if has_helmet:\n",
        "                color = (255, 0, 0) # íŒŒë€ìƒ‰ (OpenCVëŠ” BGR)\n",
        "                label = \"Safe (Outside)\"                            # ğŸ”µ êµ¬ì—­ ì™¸ ì•ˆì „\n",
        "            else:\n",
        "                color, label = (0, 255, 255), \"Warning: Helmet?\"    # ğŸŸ¡ êµ¬ì—­ ì™¸ ì£¼ì˜\n",
        "\n",
        "        # ì‹œê°í™”\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
        "        (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        cv2.rectangle(img, (x1, y1 - 25), (x1 + text_w, y1), color, -1)\n",
        "        txt_color = (0, 0, 0) if color in [(0, 255, 255), (0, 255, 0)] else (255, 255, 255)\n",
        "        cv2.putText(img, label, (x1, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.6, txt_color, 2)\n",
        "\n",
        "    print(f\"\\nğŸ“¸ ë¶„ì„ ê²°ê³¼: {os.path.basename(image_path)}\")\n",
        "    cv2_imshow(img)\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê²€ì¦ ë°ì´í„°ì…‹ì—ì„œ ëœë¤ ìƒ˜í”Œë§)\n",
        "import random\n",
        "dataset_path = '/kaggle/input/hardhat-vest-dataset-v3'\n",
        "test_images = glob.glob(os.path.join(dataset_path, '**', 'images', '**', '*.jpg'), recursive=True)\n",
        "# ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤ í™•ì¸ì„ ìœ„í•´ ëœë¤í•˜ê²Œ 3ì¥ ì„ íƒ\n",
        "sample_images = random.sample(test_images, 3) if test_images else []\n",
        "\n",
        "if model and sample_images:\n",
        "    for img_path in sample_images:\n",
        "        run_safety_analysis(model, img_path)\n",
        "else:\n",
        "    print(\"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "cYr0izZM4gIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# 7. ëª¨ë¸ ì €ì¥ ë° ë‚´ë³´ë‚´ê¸° (Export)\n",
        "# ==================================================================================\n",
        "print(\">> [7. Export] ëª¨ë¸ ë³€í™˜ ë° ì €ì¥...\")\n",
        "\n",
        "try:\n",
        "    if os.path.exists(best_model_path):\n",
        "        # ONNX í¬ë§·ìœ¼ë¡œ ë³€í™˜ (CPU ëª¨ë“œ ê¶Œì¥)\n",
        "        model.export(format='onnx', device='cpu')\n",
        "\n",
        "        print(\"\\nâœ… ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì„±ê³µ!\")\n",
        "        print(f\"   ğŸ“¦ ONNX íŒŒì¼ ìœ„ì¹˜: {best_model_path.replace('.pt', '.onnx')}\")\n",
        "        print(f\"   ğŸ’¾ PT íŒŒì¼ ìœ„ì¹˜:   {best_model_path}\")\n",
        "        print(\"\\n[ì•ˆë‚´] ì™¼ìª½ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ í•´ë‹¹ ê²½ë¡œë¥¼ ì°¾ì•„ ìš°í´ë¦­ -> ë‹¤ìš´ë¡œë“œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        print(\"âš ï¸ ì €ì¥í•  ëª¨ë¸ íŒŒì¼(best.pt)ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "print(\"\\nğŸ‰ ëª¨ë“  í”„ë¡œì íŠ¸ ê³¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
      ],
      "metadata": {
        "id": "ek5on5vP4eNh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}